# Learn from the Nature: reinforcement learning using Genetic Algorithm (GA)

In this post, we will try to understand the basic mechanism behind genetic algorithm and use it to solve the reinforcement learning problem. See below how well genetic algorithm was able to balance cartpole after the 6th episode only.

<figure>
  <video controls width="100%" src="{{ site.baseurl }}/images/cartpole.mp4" autoplay loop/>
</figure>

Okay, before diving deep into the GA let me answer some ifs and buts, the whys and why nots with a brief background on meta heuristic – a class to which it belongs.

## Why not the descent down the gradient? 
Gradient descent can be the go-to algorithm if you have that most desirable continuous, differentiable, unimodal function to detect “The” optimal point but hey welcome to the real world to realise that problems are not this smooth. Given a discrete function and there goes our Mr. dependable out of the bag. Also, don’t ask me to walk the pitted path of those “locals” to reach the “global” goal with normal descent. I heard somebody mentioning NP-hard.

Of course that doesn’t imply if encountered with such patchy problem then call it a quit and thus let me introduce you to the meta world where no heuristic information is required to seek the solution. 
## What is Metaheuristic?
Word “meta” can be linked to some degree of randomness induced in the model. Hey, don’t be just blown away by the word random as you will witness how these randomizations itself will provide a guided search towards the best solution.

## How this pool of population-based metaheuristic algorithms work?
Suppose you are provided with a problem about which you don’t have any idea and in reality, it looks like below (wow, what a nightmare):
![surface.png]("/images/surface.png")
