# Learn from the Nature: reinforcement learning using Genetic Algorithm (GA)
In this post, we will try to understand the basic mechanism behind genetic algorithm and use it to solve the reinforcement learning problem. See below how well genetic algorithm was able to balance cartpole after the 6th episode only.

<figure>
  <video controls width="100%" src="{{ site.baseurl }}/images/cartpole.mp4" autoplay loop/>
</figure>

Okay, before diving deep into the GA let me answer some ifs and buts, the whys and why nots with a brief background on meta heuristic – a class to which it belongs.

## Why not the descent down the gradient? 
Gradient descent can be the go-to algorithm if you have that most desirable continuous, differentiable, unimodal function to detect “The” optimal point but hey welcome to the real world to realise that problems are not this smooth. Given a discrete function and there goes our Mr. dependable out of the bag. Also, don’t ask me to walk the pitted path of those “locals” to reach the “global” goal with normal descent. I heard somebody mentioning NP-hard.

Of course that doesn’t imply if encountered with such patchy problem then call it a quit and thus let me introduce you to the meta world where no heuristic information is required to seek the solution. 
## What is Metaheuristic?
Word “meta” can be linked to some degree of randomness induced in the model. Hey, don’t be just blown away by the word random as you will witness how these randomizations itself will provide a guided search towards the best solution.

## How this pool of population-based metaheuristic algorithms work?
Suppose you are provided with a problem about which you don’t have any idea and in reality, it looks like below (wow, what a nightmare):

![](/images/surface.png)

But you have this output(savior) function which returns the fitness value of your imagined solutions.

So, it starts with some random initialization (feel free to seed some points with heuristic solutions to reduce the search space but don’t dare to get rid of that rich diversity by eliminating randomness). Now, the whole exercise will reduce to exploitation versus exploration. We will select the fittest solution by exploiting the given population but also try to avoid those local traps (in case of uglier surface like above) by tweaking those individuals and exploring more surfaces. Continue till convergence or end condition.

This is the broad idea on which these population-based method are based. With this premise in mind, let’s call GA for some action.


## Understanding Genetics
The name pretty much says from where it takes the inspiration but will definitely come to the fancy terminology used to describe the process. Before that an overview:

We start with initializing a pool of random solutions (consider this as selecting random vector of points on the high dimensional surface). Then, we determine the value of these random points represented in the form of weights from the available output function. Go on to select the better ones among the rest (survival of the fittest).

From the view point that new solution created will inherit better characteristic from the former ones, some information exchange takes place between the selected solutions (take it as exchanging good traits between any two solutions).

It might happen with high probability (based on the search space of initial population) that part of the space remains unexplored. This may return sub optimal solution and to ward off this fear some weights of the created solution can be tweaked to explore the unentered boundaries.

Linking above phenomena with actual terminology, we can define:

*	**Population** – pool of individual solution. 
*	**Child and parent** – a child is the tweaked copy of a candidate solution (parent)
*	**Chromosome** – an individual or single solution  
*	**Genes** – a particular position (point on the vector) in a chromosome
*	**Allele** – a particular setting (arrangement of points on the vector) of a gene
*	**Fitness function** – calculates the profit/cost (solution domain) associated with an individual
*	**Representation** – How an individual in the population is represented internally. These search spaces are broadly categorized into 2 classes:
 1.	Phenotypic: Individual represent solution internally exactly as they are represented externally
 1.	Genotypic: Individuals internally represent solutions encoded in a universal representation language (binary encoding)
  
*	**Crossover** – Swapping section of two parents to produce children (information exchange between any two individuals)
*	**Mutation** – Randomly tweaking candidate solution (for exploration)



## Pseudo Code-
*	**INITIALIZATION** – Initialize with some random solution of population size m. It can be viewed as a measure of degree of parallel search 
*	**SELECTION** – Select individuals for reproduction by giving preference to fittest individuals also viewed as selection pressure. This step can be related to exploitation phase.
*	**CROSSOVER** – Produce m offspring for next generation after tweaking selected parents. We will dig deep into types of crossover in next section.
*	**MUTATION** – Mutate certain children to induce variation in the population. It can be linked to exploration
*	Continue until certain end time/ best solution found.


For solving the cartpole, a simple 2 layered neural net was created which is used for initialization. Population of size "num_agents" is generated using this net to initialize agents with different weights.

```python
def population(num_agents):
    
    agents = []
    for _ in range(num_agents):
        #Class LunarLander(neural net) is called to initialize weights of agents
        agent = LunarLander().to(device)
        
        for param in agent.parameters():
            param.requires_grad = False
            
        agents.append(agent)
                
    return agents
```

Success of GAs is attributed to the phenomenon of survival of the fittest. It is proven through schema theorem stated below that fit individuals grow rapidly through generations (you can refer to Goldberg’s explanation for this).

#### Schema Theorem
A schema is a template that identifies similarity of string (vector of points) at certain position. High fitness vectors may contain certain pattern of points embedded at certain position.

For example, consider a length 7 schema ${\ast}1{\ast}{\ast}0{\ast}1$ that describes the set of all vectors of length 7 with fixed values at second, fifth and seventh position. The ${\ast}$ symbol implies that these positions can take any binary value. Also, a schema can be defined by 2 main attributes: order and defining length. The order O(H) of a schema is defined as the number of fixed values in the template, while the defining length  is the distance between the first and last fixed positions. In the above example, the order is 3 and its defining length is 5. The fitness of a schema is the average fitness of all strings matching the schema. The fitness of a string is a measure of the value of the encoded problem solution, as computed by a problem-specific evaluation function.

Schema theorem states that short, low order, above average schemata receive exponentially increasing trials in successive generations.
